{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26f36e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec56b75",
   "metadata": {},
   "source": [
    "# 1\n",
    "В файле «baseball.csv» находится выборка с информацией по игрокам в бейсбол, включая\n",
    "статистику их результативности, время участия в играх, лига, зарплата и т.д. Name (имя) нужно\n",
    "считать идентификатором записи. Загрузите этот файл и произведите следующие действия для\n",
    "кластерного анализа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f33569be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"baseball.csv\")\n",
    "df = df.set_index(\"Name\")\n",
    "\n",
    "df_base = df.copy()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041e0c80",
   "metadata": {},
   "source": [
    "# 2\n",
    "Обработка пропусков. Переменная Salary (и log Salary) может содержать пропуски,\n",
    "произведите подстановку пропусков методом согласно вашему варианту. Пересчитайте\n",
    "logSalary как log(1+Salary), чтобы получить более симметричное распределение.\n",
    "\n",
    "KnnImputer (neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4988b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_imp = KNNImputer(n_neighbors=5)\n",
    "\n",
    "df[[\"Salary\", \"logSalary\"]] = knn_imp.fit_transform(df[[\"Salary\", \"logSalary\"]])\n",
    "\n",
    "df[\"logSalary\"] = np.log(1 + df[\"Salary\"])\n",
    "\n",
    "df_after_2 = df.copy()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7bfdff",
   "metadata": {},
   "source": [
    "# 3\n",
    "Нормализация переменных – приведите числовые переменные к близким шкалам с помощью\n",
    "методов для вашего варианта и закодируйте категориальные с помощью OneHotEncoder.\n",
    "\n",
    "MaxAbsScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b290b556",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = [\n",
    "    \"CrAtBat\", \"CrBB\", \"CrHits\", \"CrHome\", \"CrRbi\", \"CrRuns\", \"logSalary\", \"nAssts\", \"nAtBat\", \"nBB\", \"nError\",\n",
    "    \"nHits\", \"nHome\", \"nOuts\", \"nRBI\", \"nRuns\", \"Salary\", \"YrMajor\"\n",
    "]\n",
    "\n",
    "nominal = [\n",
    "    \"Div\", \"Division\", \"League\", \"Position\", \"Team\",\n",
    "]\n",
    "\n",
    "df[interval] = MaxAbsScaler().fit_transform(df[interval])\n",
    "\n",
    "# df = pd.get_dummies(df, columns=nominal)\n",
    "\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "ohe.fit(df[nominal])\n",
    "\n",
    "temp_df = pd.DataFrame(data=ohe.transform(df[nominal]), columns=ohe.get_feature_names_out(), index = df.index)\n",
    "df.drop(columns=nominal, inplace=True)\n",
    "df = pd.concat([df, temp_df], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b2721b",
   "metadata": {},
   "source": [
    "# 4\n",
    "С помощью восходящей иерархической кластеризации с выбранными параметрами\n",
    "расстояния согласно вашему варианту постройте кластерную модель данных и дендрограмму\n",
    "для топ 20 кластеров.\n",
    "\n",
    "link=average, dist=euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "319b3d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dendrogram(model, **kwargs):\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "    linkage_matrix = np.column_stack([model.children_, model.distances_, counts]).astype(float)\n",
    "    dendrogram(linkage_matrix, **kwargs)\n",
    "    plt.xlabel(\"Количество наблюдений в узле\")\n",
    "\n",
    "\n",
    "model = AgglomerativeClustering(linkage=\"average\", metric=\"euclidean\", n_clusters=20, compute_distances=True)\n",
    "model = model.fit(df)\n",
    "plot_dendrogram(model, truncate_mode=\"level\", p=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7d9ecb",
   "metadata": {},
   "source": [
    "# 5\n",
    "Рассчитайте значение критерия pseudoF для вариантов кластеризации 2-20 кластеров,\n",
    "постройте график зависимости критерия от числа кластеров и выберите оптимальное (первый\n",
    "локальный пик критерия при обходе от малого числа кластеров к большому). Отметьте точку\n",
    "на графике. Сколько кластеров получилось?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f18e807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_dist_to_center(X):\n",
    "    center = np.mean(X, axis = 0)\n",
    "    return ((X - center)**2).values.sum()\n",
    "\n",
    "\n",
    "def choose_num_clusters(X, max_clust = 30):\n",
    "    N = X.shape[0]\n",
    "    Q = sum_dist_to_center(X)\n",
    "    pseudo_f = np.array([])\n",
    "    for G in range(2, max_clust + 1):\n",
    "        clustering = KMeans(n_clusters = G, n_init=\"auto\").fit(X)\n",
    "        W = 0\n",
    "        for l in range(G):\n",
    "            elems = X[clustering.labels_ == l]\n",
    "            W += sum_dist_to_center(elems)\n",
    "        fisher_stat = ((Q - W)/(G - 1))/(W/(N - G))\n",
    "        pseudo_f = np.append(pseudo_f, fisher_stat)\n",
    "        \n",
    "    plt.plot(range(2, max_clust + 1), pseudo_f)\n",
    "    ind_best_clust = np.argmax(pseudo_f)\n",
    "    plt.scatter(ind_best_clust + 2, pseudo_f[ind_best_clust], color=\"r\", marker=\"D\", s=50)\n",
    "    plt.xlabel(\"Number of clusters\")\n",
    "    plt.ylabel(\"Pseudo-F\")\n",
    "    return ind_best_clust + 2\n",
    "\n",
    "\n",
    "k = choose_num_clusters(df, max_clust=20)\n",
    "k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0fcacf",
   "metadata": {},
   "source": [
    "# 6\n",
    "С помощью метода проекции для вашего варианта постройте отображение на плоскость,\n",
    "цветом точки укажите номер кластера.\n",
    "\n",
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab0bf6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "features = pca.fit_transform(df)\n",
    "\n",
    "plt.scatter(features[:, 0], features[:, 1], c=model.labels_)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65788278",
   "metadata": {},
   "source": [
    "# 7\n",
    "Выполните кластеризацию сферическими кластерами с прототипом методом из вашего\n",
    "варианта, также постройте проекцию как на шаге 6, определите наиболее типичного\n",
    "представителя (по имени) в каждом из кластеров.\n",
    "\n",
    "EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66a9599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gm = GaussianMixture(n_components=k, covariance_type=\"spherical\")\n",
    "\n",
    "clusters = gm.fit_predict(df)\n",
    "\n",
    "plt.scatter(features[:, 0], features[:, 1], c=clusters)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8a8d60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = df.copy()\n",
    "df7[\"cluster\"] = clusters\n",
    "\n",
    "# for i in range(k):\n",
    "#     cur_cluster = df7[df7[\"cluster\"] == i]\n",
    "#     center = np.mean(cur_cluster, axis = 0)\n",
    "#     print(np.sqrt(((cur_cluster - center) ** 2).sum(axis=1)).sort_values().index[0])\n",
    "\n",
    "for i in range(k):\n",
    "    cur_cluster = df7[df7[\"cluster\"] == i]\n",
    "    center = pd.Series(np.append(gm.means_[i], 0), index=df7.columns)\n",
    "    print(np.sqrt(((cur_cluster - center) ** 2).sum(axis=1)).sort_values().index[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47acc388",
   "metadata": {},
   "source": [
    "# 8\n",
    "Реализуйте шаги 3-7 в виде функции или класса. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d71db544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func8(df, interval, nominal):\n",
    "    #plt.clf()\n",
    "    # 3\n",
    "    print(\"task 3\")\n",
    "    df[interval] = MaxAbsScaler().fit_transform(df[interval])\n",
    "\n",
    "    # df = pd.get_dummies(df, columns=nominal)\n",
    "\n",
    "    ohe = OneHotEncoder(sparse_output=False)\n",
    "    ohe.fit(df[nominal])\n",
    "\n",
    "    temp_df = pd.DataFrame(data=ohe.transform(df[nominal]), columns=ohe.get_feature_names_out(), index = df.index)\n",
    "    df.drop(columns=nominal, inplace=True)\n",
    "    df = pd.concat([df, temp_df], axis=1)\n",
    "    \n",
    "    # 4\n",
    "    print(\"task 4\")\n",
    "    model = AgglomerativeClustering(linkage=\"average\", metric=\"euclidean\", n_clusters=20, compute_distances=True)\n",
    "    model = model.fit(df)\n",
    "    plot_dendrogram(model, truncate_mode=\"level\", p=4)\n",
    "    plt.show()\n",
    "    \n",
    "    # 5\n",
    "    print(\"task 5\")\n",
    "    k = choose_num_clusters(df, max_clust=20)\n",
    "    plt.show()\n",
    "    print(k)\n",
    "    \n",
    "    # 6\n",
    "    print(\"task 6\")\n",
    "    pca = PCA(n_components=2)\n",
    "    features = pca.fit_transform(df)\n",
    "\n",
    "    plt.scatter(features[:, 0], features[:, 1], c=model.labels_)\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.show()\n",
    "    \n",
    "    # 7\n",
    "    print(\"task 7\")\n",
    "    gm = GaussianMixture(n_components=k, covariance_type=\"spherical\")\n",
    "\n",
    "    clusters = gm.fit_predict(df)\n",
    "\n",
    "    plt.scatter(features[:, 0], features[:, 1], c=clusters)\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.show()\n",
    "    \n",
    "    df7 = df.copy()\n",
    "    df7[\"cluster\"] = clusters\n",
    "\n",
    "    # for i in range(k):\n",
    "    #     cur_cluster = df7[df7[\"cluster\"] == i]\n",
    "    #     center = np.mean(cur_cluster, axis = 0)\n",
    "    #     print(np.sqrt(((cur_cluster - center) ** 2).sum(axis=1)).sort_values().index[0])\n",
    "    \n",
    "    for i in range(k):\n",
    "        cur_cluster = df7[df7[\"cluster\"] == i]\n",
    "        center = pd.Series(np.append(gm.means_[i], 0), index=df7.columns)\n",
    "        print(np.sqrt(((cur_cluster - center) ** 2).sum(axis=1)).sort_values().index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd6cc926",
   "metadata": {},
   "outputs": [],
   "source": [
    "func8(df_after_2, interval, nominal)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
