{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f36e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from varclushi import VarClusHi\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler, Normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec56b75",
   "metadata": {},
   "source": [
    "# 1\n",
    "В файле «baseball.csv» находится выборка с информацией по игрокам в бейсбол, включая\n",
    "статистику их результативности, время участия в играх, лига, зарплата и т.д. Name (имя) нужно\n",
    "считать идентификатором записи. Загрузите этот файл и произведите следующие действия для\n",
    "кластерного анализа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33569be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"baseball.csv\")\n",
    "df = df.set_index(\"Name\")\n",
    "\n",
    "df_base = df.copy()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041e0c80",
   "metadata": {},
   "source": [
    "# 2\n",
    "Обработка пропусков. Переменная Salary (и log Salary) может содержать пропуски,\n",
    "произведите подстановку пропусков методом согласно вашему варианту. Пересчитайте\n",
    "logSalary как log(1+Salary), чтобы получить более симметричное распределение.\n",
    "\n",
    "KnnImputer (neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4988b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_imp = KNNImputer(n_neighbors=5)\n",
    "\n",
    "df[[\"Salary\", \"logSalary\"]] = knn_imp.fit_transform(df[[\"Salary\", \"logSalary\"]])\n",
    "\n",
    "df[\"logSalary\"] = np.log(1 + df[\"Salary\"])\n",
    "\n",
    "df_after_2 = df.copy()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7bfdff",
   "metadata": {},
   "source": [
    "# 3\n",
    "Нормализация переменных – приведите числовые переменные к близким шкалам с помощью\n",
    "методов для вашего варианта и закодируйте категориальные с помощью OneHotEncoder.\n",
    "\n",
    "MaxAbsScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b290b556",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = [\n",
    "    \"CrAtBat\", \"CrBB\", \"CrHits\", \"CrHome\", \"CrRbi\", \"CrRuns\", \"logSalary\", \"nAssts\", \"nAtBat\", \"nBB\", \"nError\",\n",
    "    \"nHits\", \"nHome\", \"nOuts\", \"nRBI\", \"nRuns\", \"Salary\", \"YrMajor\"\n",
    "]\n",
    "\n",
    "nominal = [\n",
    "    \"Div\", \"Division\", \"League\", \"Position\", \"Team\",\n",
    "]\n",
    "\n",
    "df[interval] = MaxAbsScaler().fit_transform(df[interval])\n",
    "\n",
    "# df = pd.get_dummies(df, columns=nominal)\n",
    "\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "ohe.fit(df[nominal])\n",
    "\n",
    "temp_df = pd.DataFrame(data=ohe.transform(df[nominal]), columns=ohe.get_feature_names_out(), index = df.index)\n",
    "df.drop(columns=nominal, inplace=True)\n",
    "df = pd.concat([df, temp_df], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b2721b",
   "metadata": {},
   "source": [
    "# 4\n",
    "С помощью восходящей иерархической кластеризации с выбранными параметрами\n",
    "расстояния согласно вашему варианту постройте кластерную модель данных и дендрограмму\n",
    "для топ 20 кластеров.\n",
    "\n",
    "link=average, dist=euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319b3d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dendrogram(model, **kwargs):\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "    linkage_matrix = np.column_stack([model.children_, model.distances_, counts]).astype(float)\n",
    "    dendrogram(linkage_matrix, **kwargs)\n",
    "    plt.xlabel(\"Количество наблюдений в узле\")\n",
    "\n",
    "\n",
    "model = AgglomerativeClustering(linkage=\"average\", metric=\"euclidean\", n_clusters=20, compute_distances=True)\n",
    "model = model.fit(df)\n",
    "plot_dendrogram(model, truncate_mode=\"level\", p=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7d9ecb",
   "metadata": {},
   "source": [
    "# 5\n",
    "Рассчитайте значение критерия pseudoF для вариантов кластеризации 2-20 кластеров,\n",
    "постройте график зависимости критерия от числа кластеров и выберите оптимальное (первый\n",
    "локальный пик критерия при обходе от малого числа кластеров к большому). Отметьте точку\n",
    "на графике. Сколько кластеров получилось?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f18e807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_dist_to_center(X):\n",
    "    center = np.mean(X, axis = 0)\n",
    "    return ((X - center)**2).values.sum()\n",
    "\n",
    "\n",
    "def choose_num_clusters(X, max_clust = 30):\n",
    "    N = X.shape[0]\n",
    "    Q = sum_dist_to_center(X)\n",
    "    pseudo_f = np.array([])\n",
    "    for G in range(2, max_clust + 1):\n",
    "        clustering = KMeans(n_clusters = G, n_init=\"auto\").fit(X)\n",
    "        W = 0\n",
    "        for l in range(G):\n",
    "            elems = X[clustering.labels_ == l]\n",
    "            W += sum_dist_to_center(elems)\n",
    "        fisher_stat = ((Q - W)/(G - 1))/(W/(N - G))\n",
    "        pseudo_f = np.append(pseudo_f, fisher_stat)\n",
    "        \n",
    "    plt.plot(range(2, max_clust + 1), pseudo_f)\n",
    "    ind_best_clust = np.argmax(pseudo_f)\n",
    "    plt.scatter(ind_best_clust + 2, pseudo_f[ind_best_clust], color=\"r\", marker=\"D\", s=50)\n",
    "    plt.xlabel(\"Number of clusters\")\n",
    "    plt.ylabel(\"Pseudo-F\")\n",
    "    return ind_best_clust + 2\n",
    "\n",
    "\n",
    "k = choose_num_clusters(df, max_clust=20)\n",
    "k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0fcacf",
   "metadata": {},
   "source": [
    "# 6\n",
    "С помощью метода проекции для вашего варианта постройте отображение на плоскость,\n",
    "цветом точки укажите номер кластера.\n",
    "\n",
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0bf6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "features = pca.fit_transform(df)\n",
    "\n",
    "plt.scatter(features[:, 0], features[:, 1], c=model.labels_)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65788278",
   "metadata": {},
   "source": [
    "# 7\n",
    "Выполните кластеризацию сферическими кластерами с прототипом методом из вашего\n",
    "варианта, также постройте проекцию как на шаге 6, определите наиболее типичного\n",
    "представителя (по имени) в каждом из кластеров.\n",
    "\n",
    "EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a9599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gm = GaussianMixture(n_components=k, covariance_type=\"spherical\")\n",
    "\n",
    "clusters = gm.fit_predict(df)\n",
    "\n",
    "plt.scatter(features[:, 0], features[:, 1], c=clusters)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a8d60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = df.copy()\n",
    "df7[\"cluster\"] = clusters\n",
    "\n",
    "# for i in range(k):\n",
    "#     cur_cluster = df7[df7[\"cluster\"] == i]\n",
    "#     center = np.mean(cur_cluster, axis = 0)\n",
    "#     print(np.sqrt(((cur_cluster - center) ** 2).sum(axis=1)).sort_values().index[0])\n",
    "\n",
    "for i in range(k):\n",
    "    cur_cluster = df7[df7[\"cluster\"] == i]\n",
    "    center = pd.Series(np.append(gm.means_[i], 0), index=df7.columns)\n",
    "    print(np.sqrt(((cur_cluster - center) ** 2).sum(axis=1)).sort_values().index[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47acc388",
   "metadata": {},
   "source": [
    "# 8\n",
    "Реализуйте шаги 3-7 в виде функции или класса. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71db544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func8(df8, interval, nominal):\n",
    "    df = df8.copy()\n",
    "    \n",
    "    # 3\n",
    "    print(\"task 3\")\n",
    "    df[interval] = MaxAbsScaler().fit_transform(df[interval])\n",
    "\n",
    "    # df = pd.get_dummies(df, columns=nominal)\n",
    "\n",
    "    ohe = OneHotEncoder(sparse_output=False)\n",
    "    ohe.fit(df[nominal])\n",
    "\n",
    "    temp_df = pd.DataFrame(data=ohe.transform(df[nominal]), columns=ohe.get_feature_names_out(), index = df.index)\n",
    "    df.drop(columns=nominal, inplace=True)\n",
    "    df = pd.concat([df, temp_df], axis=1)\n",
    "    \n",
    "    # 4\n",
    "    print(\"task 4\")\n",
    "    model = AgglomerativeClustering(linkage=\"average\", metric=\"euclidean\", n_clusters=20, compute_distances=True)\n",
    "    model = model.fit(df)\n",
    "    plot_dendrogram(model, truncate_mode=\"level\", p=4)\n",
    "    plt.show()\n",
    "    \n",
    "    # 5\n",
    "    print(\"task 5\")\n",
    "    k = choose_num_clusters(df, max_clust=20)\n",
    "    plt.show()\n",
    "    print(k)\n",
    "    \n",
    "    # 6\n",
    "    print(\"task 6\")\n",
    "    pca = PCA(n_components=2)\n",
    "    features = pca.fit_transform(df)\n",
    "\n",
    "    plt.scatter(features[:, 0], features[:, 1], c=model.labels_)\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.show()\n",
    "    \n",
    "    # 7\n",
    "    print(\"task 7\")\n",
    "    gm = GaussianMixture(n_components=k, covariance_type=\"spherical\")\n",
    "\n",
    "    clusters = gm.fit_predict(df)\n",
    "\n",
    "    plt.scatter(features[:, 0], features[:, 1], c=clusters)\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.show()\n",
    "    \n",
    "    df7 = df.copy()\n",
    "    df7[\"cluster\"] = clusters\n",
    "\n",
    "    # for i in range(k):\n",
    "    #     cur_cluster = df7[df7[\"cluster\"] == i]\n",
    "    #     center = np.mean(cur_cluster, axis = 0)\n",
    "    #     print(np.sqrt(((cur_cluster - center) ** 2).sum(axis=1)).sort_values().index[0])\n",
    "    \n",
    "    for i in range(k):\n",
    "        cur_cluster = df7[df7[\"cluster\"] == i]\n",
    "        center = pd.Series(np.append(gm.means_[i], 0), index=df7.columns)\n",
    "        print(np.sqrt(((cur_cluster - center) ** 2).sum(axis=1)).sort_values().index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7d2079",
   "metadata": {},
   "outputs": [],
   "source": [
    "func8(df_after_2, interval, nominal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d269d0e",
   "metadata": {},
   "source": [
    "# 9\n",
    "Произведите дополнительную предобработку набора данных, сделав распределения\n",
    "переменных более симметричными. Для этого с помощью гисторамм или метода describe в\n",
    "dataframe или метода skew найдите переменные с одной модой и тяжелым правым хвостом,\n",
    "примените к ним преобразование log(1+x). Запустите функцию из шага 8. Как изменилось\n",
    "число кластеров, проекции и лучшие представители. Как считаете, субъективное качество\n",
    "кластеризации изменилось? Как и почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cc8b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df10 = df_after_2.copy()\n",
    "\n",
    "right_skewed_vars = []\n",
    "for col in interval:\n",
    "    if df_after_2[col].skew() > 1 and df_after_2[col].mode().count() == 1:\n",
    "        right_skewed_vars.append(col)\n",
    "        \n",
    "for col in right_skewed_vars:\n",
    "    df_after_2[col] = np.log1p(df_after_2[col])\n",
    "\n",
    "func8(df_after_2, interval, nominal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1818611f",
   "metadata": {},
   "source": [
    "Число кластеров осталось прежним. Проекции примерно остались прежними. Можно предположить, что субъективное качество кластеризации не изменилось значительно. Однако, изменение лучших представителей может указывать на изменения внутрикластерной структуры или на изменения в распределении данных, которые могут быть интересны для дальнейшего анализа."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f9fa97",
   "metadata": {},
   "source": [
    "# 10\n",
    "Отберите 5 наиболее значимых переменных с помощью метода из вашего варианта. Запустите\n",
    "функцию из шага 8. Как изменилось число кластеров, проекции и лучшие представители. Как\n",
    "считаете, субъективное качество кластеризации изменилось? Как и почему?\n",
    "\n",
    "VarClus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cb1ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df10[interval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c009a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nvar = 5\n",
    "\n",
    "clusters = VarClusHi(X, maxeigval2=0.8, maxclus=nvar)\n",
    "clusters.varclus()\n",
    "clusters.info\n",
    "\n",
    "max_RS_Ratio = clusters.rsquare.sort_values(by=[\"Cluster\", \"RS_Ratio\"], ascending=[True, False])\n",
    "\n",
    "vars = []\n",
    "\n",
    "for i in range(nvar):\n",
    "    vars.append(max_RS_Ratio[max_RS_Ratio[\"Cluster\"] == i][\"Variable\"].values[0])\n",
    "    #print(max_RS_Ratio[max_RS_Ratio[\"Cluster\"] == i][\"Variable\"].values[0])\n",
    "\n",
    "print(*vars)\n",
    "\n",
    "func8(df10[vars + nominal], vars, nominal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccd5784",
   "metadata": {},
   "source": [
    "Число кластеров осталось прежним. Проекции примерно остались прежними. Можно предположить, что субъективное качество кластеризации не изменилось значительно. Однако, изменение лучших представителей может указывать на изменения внутрикластерной структуры или на изменения в распределении данных, которые могут быть интересны для дальнейшего анализа."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2550715",
   "metadata": {},
   "source": [
    "# 11\n",
    "«Творческое задание» на поиск аномалий. Загрузите файл mnist_small.csv. Данный набор\n",
    "данных содержит подмножество эталонного набора данных рукописных цифр MNIST. 5923\n",
    "картинок 28x28 пикселей с изображением нуля и 76 картинок с изображением шестерки.\n",
    "Задача состоит в том, чтобы с использованием методов обучения без учителя для своего\n",
    "варианта построить одноклассовую модель на основе поиска аномалий, которая максимально\n",
    "хорошо отфильтрует шестерки (как аномалии) от нулей (как основной выборки). Признаки\n",
    "картинок описываются их координатами (в названии переменных, например «10x12») и\n",
    "значением яркости точки по этим координатам. Подбирая параметры метода и преобразуя\n",
    "признаки как посчитаете нужным, но не используя при этом информацию о label, постройте\n",
    "модель выявления аномалий с ERR меньше 0.2.\n",
    "\n",
    "KPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c10a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(df):\n",
    "    fpr, tpr, threshold = metrics.roc_curve(df[\"label\"], df[\"pred\"])\n",
    "    \n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.plot([0, 1], [1, 0])\n",
    "    plt.axvline(x = 0.2, color=\"red\")\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46e3b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"mnist_small.csv\")\n",
    "\n",
    "df['label'] = df['label'].replace(6,1)\n",
    "\n",
    "X = df.copy()\n",
    "X = X.set_index(\"label\")\n",
    "\n",
    "X = MaxAbsScaler().fit_transform(X)\n",
    "X = pd.DataFrame(X)\n",
    "\n",
    "kernel_pca = KernelPCA(\n",
    "    n_components=2,\n",
    "    kernel=\"rbf\",\n",
    "    fit_inverse_transform=True,\n",
    "    n_jobs=-1)\n",
    "\n",
    "kernel_pca.fit(X)\n",
    "\n",
    "X_pca = kernel_pca.transform(X)\n",
    "\n",
    "E = abs(X.values-kernel_pca.inverse_transform(X_pca))\n",
    "\n",
    "ET = np.apply_along_axis(np.linalg.norm, 1, E)\n",
    "\n",
    "df[\"pred\"] = ET\n",
    "\n",
    "plot_roc(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8e2ab4",
   "metadata": {},
   "source": [
    "# 12\n",
    "Постройте ROC кривую с ERR. Выведите 4 картинки с числами (28 на 28 пикселей):\n",
    "- самый типичный “0” – true negative с минимальной аномальностью\n",
    "- самая аномальная “6” – true positive с максимальной аномальностью\n",
    "- самый нетипичный “0” – false positive с максимальной аномальностью\n",
    "- самая неаномальная “6” – false negative с минимальной аномальностью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0852c383",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaf6540",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = df[df[\"label\"] == 0]\n",
    "sixes = df[df[\"label\"] == 1]\n",
    "\n",
    "plt.imshow(zeros[zeros[\"pred\"] == zeros[\"pred\"].min()].values[0][1:-1].reshape(28, 28))\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(zeros[zeros[\"pred\"] == zeros[\"pred\"].max()].values[0][1:-1].reshape(28, 28))\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(sixes[sixes[\"pred\"] == sixes[\"pred\"].min()].values[0][1:-1].reshape(28, 28))\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(sixes[sixes[\"pred\"] == sixes[\"pred\"].max()].values[0][1:-1].reshape(28, 28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc54015",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
